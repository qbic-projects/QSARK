---
title: "Sarek Paper"
subtitle: "Dataflow investigation"
author: "Friederike Hanssen"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document:
    toc: true                               # table of contents
    toc_float: true                        # float the table of contents to the left of the main document content
    toc_depth: 3                            # header levels 1,2,3
    theme: default
    number_sections: true                   # add section numbering to headers
    df_print: paged                         # tables are printed as an html table with support for pagination over rows and columns
    css: ./qbic-style.css
    highlight: pygments
    pdf_document: true
---

<!-- QBiC Logo -->

<img src="./QBiCLogo.png" style="position:absolute;top:0px;right:0px;" height="120" width="120"/>

::: watermark
QBiC
:::

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Import all R libraries
library(dplyr)
library(patchwork)
library(forcats)
library(ggplot2)
library(cowplot)
library(knitr)
library(kableExtra)
library(ggpubr)
library(viridisLite)
library(tidyr)
library(ggpattern)

theme_set(theme_grey())
results_folder <- "results/dataflow/"
dir.create(results_folder)

source("./functions.R")
```

------------------------------------------------------------------------

# Introduction

These experiments investigate how splitting affects runtime, and storage usage. CPU & memory were kept at the same values if at all possible

## **Goal**

We added more options to parallelise along the genome.

### Run commands

    nextflow run nf-core/sarek -r 3.1.1 -profile cfc --input --outdir -c trace.config -c custom.config --nucleotides_per_second 

    custom.config

This runs through mapping, duplicate marking, BQSR, and QC, Variant calling for BWA & non-spark GATK implementation.

# Loading the dataset

Loading all the individual samples. Print sample summary if possible (e.g. metadata sheet).

| name               | nucleotides_per_second (number of intervals) | num of cpus for fastp         | tower id                                                                                | work sizes | trace |
|----------|----------|----------|----------------------|----------|----------|
| fastp4_intervals78 | 10001 (78)                                   | 4, \--split_fastq 10000000000 | <https://cfgateway1.zdv.uni-tuebingen.de/orgs/QBiC/workspaces/cfc/watch/PE2um0F1SrwRi>  | yes        | yes   |
| fastp8_intervals40 | 70000 (40)                                   | 8, \--split_fastq 500000000   | <https://cfgateway1.zdv.uni-tuebingen.de/orgs/QBiC/workspaces/cfc/watch/52L0P2tE99JYXs> | yes        | yes   |
| fastp16_intervals1 | 5000000 (1)                                  | 16, \--split_fastq 100000000  | <https://cfgateway1.zdv.uni-tuebingen.de/orgs/QBiC/workspaces/cfc/watch/2uPwaXSKrcUaKq> | yes        | yes   |
| fastp0_intervals20 | 200000 (21)                                  | 0, \--split-fastq 0           | <http://cfgateway1.zdv.uni-tuebingen.de/orgs/QBiC/workspaces/cfc/watch/5iFlE6AEOimMO9>  | yes        | yes   |

```{r echo=FALSE}

## Fastp 0, intervals 20
storage_fastp0_intervals20 <- read.csv(file = '../data/intervals/fastp0_intervals20/folder_size.tsv', sep = "\t", stringsAsFactors = FALSE, header = FALSE)
execution_fastp0_intervals20 <- read.csv(file = '../data/intervals/fastp0_intervals20/execution_trace_2023-02-25_22-10-44.txt', sep = "\t", stringsAsFactors = FALSE)

## Fastp 4, intervals 78
storage_fastp4_intervals78 <- read.csv(file = '../data/intervals/fastp4_intervals78/folder_size.tsv', sep = "\t", stringsAsFactors = FALSE, header = FALSE)
execution_fastp4_intervals78 <- read.csv(file = '../data/intervals/fastp4_intervals78/execution_trace_2023-02-23_12-02-57.txt', sep = "\t", stringsAsFactors = FALSE)

## Fastp 8, intervals 40
storage_fastp8_intervals40 <- read.csv(file = '../data/intervals/fastp8_intervals40/folder_size.tsv', sep = "\t", stringsAsFactors = FALSE, header = FALSE)
execution_fastp8_intervals40 <- read.csv(file = '../data/intervals/fastp8_intervals40/execution_trace_2023-02-22_15-42-27.txt', sep = "\t", stringsAsFactors = FALSE)

## Fastp 12, intervals 124
execution_fastp12_intervals124_preprocessing <- read.csv(file = '../data/bam_vs_cram/results_new_cfc/data/cram/cram_nospark_preprocessing_1/execution_trace_2022-11-29_16-01-52.txt', sep = "\t", stringsAsFactors = FALSE)
execution_fastp12_intervals124_variantcalling <- read.csv(file = '../data/bam_vs_cram/results_new_cfc/data/cram/cram_variantcalling_2/execution_trace_2022-12-11_15-17-56.txt', sep = "\t", stringsAsFactors = FALSE)

storage_fastp12_intervals124_preprocessing <- read.csv(file = '../data/bam_vs_cram/results_new_cfc/data/cram/cram_nospark_preprocessing_1/folder_sizes.tsv', sep = "\t", stringsAsFactors = FALSE, header = FALSE)
storage_fastp12_intervals124_variantcalling <- read.csv(file = '../data/bam_vs_cram/results_new_cfc/data/cram/cram_variantcalling_2/folder_sizes.tsv', sep = "\t", stringsAsFactors = FALSE, header = FALSE)

execution_fastp12_intervals124 = rbind(execution_fastp12_intervals124_preprocessing, execution_fastp12_intervals124_variantcalling)
storage_fastp12_intervals124 = rbind(storage_fastp12_intervals124_preprocessing, storage_fastp12_intervals124_variantcalling)

## Fastp 16, intervals 1
storage_fastp16_intervals1 <- read.csv(file = '../data/intervals/fastp16_intervals0/folder_size.tsv', sep = "\t", stringsAsFactors = FALSE, header = FALSE)
execution_fastp16_intervals1 <- read.csv(file = '../data/intervals/fastp16_intervals0/execution_trace_2023-02-23_18-06-55.txt', sep = "\t", stringsAsFactors = FALSE)


```

# Methods

<!-- ## Clean data -->

```{r echo=FALSE}

storage_fastp0_intervals20 <- rename_storage_columns(storage_fastp0_intervals20)
storage_fastp4_intervals78 <- rename_storage_columns(storage_fastp4_intervals78)
storage_fastp8_intervals40 <- rename_storage_columns(storage_fastp8_intervals40)
storage_fastp12_intervals124 <- rename_storage_columns(storage_fastp12_intervals124)
storage_fastp16_intervals1 <- rename_storage_columns(storage_fastp16_intervals1)

# Merge both tables on key workdir
merged_fastp0_intervals20 <- merge(execution_fastp0_intervals20, storage_fastp0_intervals20, by = "workdir") %>% 
                                  mutate('fastp' = 1) %>% 
                                  mutate('intervals' = 21)
merged_fastp4_intervals78 <- merge(execution_fastp4_intervals78, storage_fastp4_intervals78, by = "workdir") %>% 
                                  mutate('fastp' = 4) %>% 
                                  mutate('intervals' = 78)
merged_fastp8_intervals40 <- merge(execution_fastp8_intervals40, storage_fastp8_intervals40, by = "workdir") %>% 
                                  mutate('fastp' = 8) %>% 
                                  mutate('intervals' = 40)
merged_fastp12_intervals124 <- merge(execution_fastp12_intervals124, storage_fastp12_intervals124, by = "workdir") %>% 
                                  mutate('fastp' = 12) %>% 
                                  mutate('intervals' = 124)
merged_fastp16_intervals1 <- merge(execution_fastp16_intervals1, storage_fastp16_intervals1, by = "workdir") %>% 
                                  mutate('fastp' = 16) %>% 
                                  mutate('intervals' = 1)


merged <- format_splitting(rbind(merged_fastp0_intervals20, 
                                 merged_fastp4_intervals78, 
                                 merged_fastp8_intervals40,
                                 merged_fastp12_intervals124, 
                                 merged_fastp16_intervals1)) %>% 
  mutate(sample_status = paste0(sample, "_", status))

```

## Mapping {.tabset .tabset-fade .tabset-pills}

```{r echo=FALSE, message = FALSE, warning=FALSE}
merge_formatted_mapping <- merged %>% filter(grepl('FASTP|BWAMEM1_MEM|GATK4_MARKDUPLICATES', process))

merged_formatted_fastp <- format_process_mapping(merge_formatted_mapping, 'FASTP')
merged_formatted_bwamem <- format_process_mapping(merge_formatted_mapping, 'BWAMEM1_MEM')
merged_formatted_markdup <- format_process_mapping(merge_formatted_mapping, 'GATK4_MARKDUPLICATES')

### Combine fastp, bwamem, markdup
merged_formatted_mapping_line_time_max <- merge_formatted_mapping %>% 
                                            group_by(fastp, simple_name, sample_status) %>% 
                                            summarise(across(realtime_min, max, .names = 'max_sample_realtime'),
                                                      across(cpu_h, sum, .names = 'sum_sample_cpuh')) %>% 
                                            group_by(fastp, sample_status) %>% 
                                            summarise(across(max_sample_realtime, sum, .names = 'sum_combined_per_sample_realtime'),
                                                      across(sum_sample_cpuh, sum, .names = 'sum_combined_per_sample_cpuh'))

merged_formatted_mapping_storage_sum <- merge_formatted_mapping %>% 
                                        group_by(fastp, sample_status) %>% 
                                        summarise(sum = sum(workdir_GB))
merged_formatted_mapping_storage_sum$fastp <- as.factor(merged_formatted_mapping_storage_sum$fastp)
```

### FastP

```{r}
plot_dataflow_single_process(df_max_time = merged_formatted_fastp$time, 
                  df = merged_formatted_fastp$process,
                  df_storage = merged_formatted_fastp$storage,
                  group = "fastp",
                  title = "FastP",
                  xaxis = "# shards",
                  outputname = "fastp",
                  results_folder = results_folder)
```

### BWA Mem

```{r echo=FALSE}
plot_dataflow_single_process(df_max_time = merged_formatted_bwamem$time, 
                  df = merged_formatted_bwamem$process,
                  df_storage = merged_formatted_bwamem$storage,
                  group = "fastp",
                  title = "BWAMem",
                  xaxis = "# shards",
                  outputname = "bwamem",
                  results_folder = results_folder
                  )
```

### Markduplicates

```{r echo=FALSE}
plot_dataflow_single_process(df_max_time = merged_formatted_markdup$time, 
                  df = merged_formatted_markdup$process,
                  df_storage = merged_formatted_markdup$storage,
                  group = "fastp",
                  title = "GATK4 Markduplicates",
                  xaxis = "# shards",
                  outputname = "markdup",
                  results_folder = results_folder
                  )
```

### Summary

```{r echo=FALSE}
mapping_summary <- plot_splitting_summary(df_time = merged_formatted_mapping_line_time_max,
                       group = "fastp",
                       xaxis = "# shards",
                       type = 'mapping',
                       df_storage = merged_formatted_mapping_storage_sum,
                       title = "Sum: Mapping processes",
                       outputname = "summary_mapping")
mapping_summary
```

## Base quality score recalibration {.tabset .tabset-fade .tabset-pills}

```{r echo=FALSE, message = FALSE, warning=FALSE}
merge_formatted_bqsr <- merged %>% filter(grepl('GATK4_BASERECALIBRATOR|GATK4_GATHERBQSRREPORTS|GATK4_APPLYBQSR|MERGE_CRAM', process))

merged_formatted_baserecalibrator <- format_process_splitting(merge_formatted_bqsr, 'GATK4_BASERECALIBRATOR')
merged_formatted_gatherbqsr <- format_process_splitting(merge_formatted_bqsr, 'GATK4_GATHERBQSRREPORTS')
merged_formatted_applybqsr <- format_process_splitting(merge_formatted_bqsr, 'GATK4_APPLYBQSR')
merged_formatted_mergecram <- format_process_splitting(merge_formatted_bqsr, 'MERGE_CRAM')

### Combine BQSR; Gather, apply, and merge
merged_formatted_bqsr_line_time_max <- merge_formatted_bqsr %>%
                                            group_by(intervals, simple_name, sample_status) %>%
                                            summarise(across(realtime_min, max, .names = 'max_sample_realtime'),
                                                      across(cpu_h, sum, .names = 'sum_sample_cpuh')) %>%                                             
                                            group_by(intervals, sample_status) %>%
                                            summarise(across(max_sample_realtime, sum, .names = 'sum_combined_per_sample_realtime'),
                                                      across(sum_sample_cpuh, sum, .names = 'sum_combined_per_sample_cpuh'))
                                            
merged_formatted_bqsr_storage_sum <- merge_formatted_bqsr %>%
                                        group_by(intervals, sample_status) %>%
                                        summarise(sum = sum(workdir_GB))
merged_formatted_bqsr_storage_sum$intervals <- as.factor(merged_formatted_bqsr_storage_sum$intervals)
```

### Baserecalibrator

```{r echo=FALSE}
plot_dataflow_single_process(df_max_time = merged_formatted_baserecalibrator$time,
                  df = merged_formatted_baserecalibrator$process,
                  df_storage = merged_formatted_baserecalibrator$storage,
                  group = "intervals",
                  title = "GATK4 Baserecalibrator",
                  xaxis = "# interval groups",
                  outputname = "baserecalibrator",
                  results_folder = results_folder)
```

### GatherBQSRReports

```{r echo=FALSE}
plot_dataflow_single_process(df_max_time = merged_formatted_gatherbqsr$time,
                  df = merged_formatted_gatherbqsr$process,
                  df_storage = merged_formatted_gatherbqsr$storage,
                  group = "intervals",
                  title = "GATK4 GatherBQSRReports",
                  xaxis = "# interval groups",
                  outputname = "gatherbqsr",
                  results_folder = results_folder)
```

### ApplyBQSR

```{r echo=FALSE}
plot_dataflow_single_process(df_max_time = merged_formatted_applybqsr$time,
                  df = merged_formatted_applybqsr$process,
                  df_storage = merged_formatted_applybqsr$storage,
                  group = "intervals",
                  title = "GATK4 ApplyBQSR",
                  xaxis = "# interval groups",
                  outputname = "applybqsr",
                  results_folder = results_folder)
```

### Merge CRAM

```{r echo=FALSE}
plot_dataflow_single_process(df_max_time = merged_formatted_mergecram$time,
                  df = merged_formatted_mergecram$process,
                  df_storage = merged_formatted_mergecram$storage,
                  group = "intervals",
                  title = "Merge CRAM",
                  xaxis = "# interval groups",
                  outputname = "mergecram",
                  results_folder = results_folder)
```

### Summary

```{r echo=FALSE}
bqsr_summary <- plot_splitting_summary(df_time = merged_formatted_bqsr_line_time_max,
                       group = "intervals",
                       xaxis = "# interval groups",
                       type = 'intervals',
                       df_storage = merged_formatted_bqsr_storage_sum,
                       title = "Sum: BQSR processes",
                       outputname = "summary_bqsr")

bqsr_summary
```

## Variant calling {.tabset .tabset-fade .tabset-pills}

```{r echo=FALSE, message = FALSE, warning=FALSE}
merge_formatted_variantcalling <- merged %>% filter(grepl('STRELKA', process))

merged_formatted_strelka <- format_process_splitting(merge_formatted_variantcalling, 'STRELKA')
#merged_formatted_freebayes <- format_process_splitting(merge_formatted_variantcalling, '^FREEBAYES')

```

### Variant callers (Somatic) {.tabset .tabset-fade .tabset-pills}

#### Mutect2

```{r echo=FALSE}
merged_formatted_mutect_time_max <-  merged %>% filter(grepl('MUTECT2_PAIRED|MERGE_MUTECT2', process)) %>%
                                            group_by(intervals, simple_name, sample_status) %>%
                                            summarise(across(realtime_min, max, .names = 'max_sample_realtime'),
                                                      across(cpu_h, sum, .names = 'sum_sample_cpuh')) %>%                             
                                            group_by(intervals, sample_status) %>%
                                            summarise(across(max_sample_realtime, sum, .names = 'sum_combined_per_sample_realtime'),
                                                      across(sum_sample_cpuh, sum, .names = 'sum_combined_per_sample_cpuh'))
                                            
merged_formatted_mutect_storage_sum <-  merged %>% filter(grepl('MUTECT2_PAIRED|MERGE_MUTECT2', process))  %>%
                                        group_by(intervals, sample_status) %>%
                                        summarise(sum = sum(workdir_GB))
merged_formatted_mutect_storage_sum$intervals <- as.factor(merged_formatted_mutect_storage_sum$intervals)

plot_splitting_summary(df_time = merged_formatted_mutect_time_max,
                       group = "intervals",
                       xaxis = "# interval groups",
                       type = 'intervals',
                       df_storage = merged_formatted_mutect_storage_sum,
                       title = "Sum: Mutect2",
                       outputname = "mutect")
```

#### Strelka

```{r echo=FALSE}
plot_dataflow_single_process(df_max_time = merged_formatted_strelka$time,
                  df = merged_formatted_strelka$process,
                  df_storage = merged_formatted_strelka$storage,
                  group = "intervals",
                  title = "Strelka",
                  xaxis = "# interval groups",
                  outputname = "strelka",
                  results_folder = results_folder)

# get the maximum value of colA for groups x and y combined
# max_merge_normal <- df %>%
#   filter(simple_name %in% c("MERGE_STRELKA", "MERGE_STRELKA_GENOME")) %>%
#   summarise(across(realtime_min, max, .names = 'max_sample_realtime'),
#             across(cpu_h, sum, .names = 'sum_sample_cpuh'))

merged_formatted_strelka_time_max <-  merged %>% filter(grepl('STRELKA_SINGLE|STRELKA_SOMATIC|MERGE_STRELKA', process)) %>%
                                            group_by(intervals, simple_name, sample_status) %>%
                                            summarise(across(realtime_min, max, .names = 'max_sample_realtime'),
                                                      across(cpu_h, sum, .names = 'sum_sample_cpuh')) %>%  
                                             group_by(intervals, sample_status) %>%
                                             filter(grepl('MERGE_STRELKA', simple_name))
                                            
#                                             summarise(across(max_sample_realtime, sum, .names = 'sum_combined_per_sample_realtime'),
#                                                       across(sum_sample_cpuh, sum, .names = 'sum_combined_per_sample_cpuh'))
#                                             
# merged_formatted_mutect_storage_sum <-  merged %>% filter(grepl('MUTECT2_PAIRED|MERGE_MUTECT2', process))  %>%
#                                         group_by(intervals, sample_status) %>%
#                                         summarise(sum = sum(workdir_GB))
# merged_formatted_mutect_storage_sum$intervals <- as.factor(merged_formatted_mutect_storage_sum$intervals)
# 
# plot_splitting_summary(df_time = merged_formatted_mutect_time_max,
#                        group = "intervals",
#                        xaxis = "# interval groups",
#                        type = 'intervals',
#                        df_storage = merged_formatted_mutect_storage_sum,
#                        title = "Sum: Mutect2",
#                        outputname = "mutect")
```

#### Freebayes

```{r echo=FALSE}
plot_dataflow_single_process(df_max_time = merged_formatted_freebayes$time,
                  df = merged_formatted_freebayes$process,
                  df_storage = merged_formatted_freebayes$storage,
                  group = "intervals",
                  title = "FreeBayes",
                  xaxis = "# interval groups",
                  outputname = "freebayes",
                  results_folder = results_folder)
```

<!-- #### Summary -->

<!-- Two things: Variantcaller max + merge vcf & all variantcallers -->

<!-- ```{r echo = FALSE} -->

<!-- merged_formatted_vc_line_time_max <- merge_formatted_variantcalling %>%  -->

<!--                                             mutate('simple_name' = case_when( -->

<!--                                               grepl("MERGE_STRELKA_INDELS", simple_name) ~ "MERGE_STRELKA", -->

<!--                                               grepl("MERGE_STRELKA_SNVS", simple_name) ~ "MERGE_STRELKA", -->

<!--                                               TRUE ~ as.character (simple_name) -->

<!--                                             )) %>% -->

<!--                                             group_by(intervals, simple_name, sample) %>% -->

<!--                                             summarise(max_y = max(realtime_min)) %>% -->

<!--                                             mutate('tool' = case_when( -->

<!--                                               grepl("STRELKA", simple_name) ~ "strelka", -->

<!--                                               grepl("MUTECT2", simple_name) ~ "mutect2", -->

<!--                                               grepl("FREEBAYES", simple_name) ~ "freebayes", -->

<!--                                               TRUE ~ "other")) %>% -->

<!--                                             group_by(intervals, tool, sample) %>% -->

<!--                                             summarise(sum = sum(max_y)) -->

<!-- merged_formatted_vc_storage_sum <- merge_formatted_variantcalling %>% -->

<!--                                         mutate('tool' = case_when( -->

<!--                                               grepl("STRELKA", simple_name) ~ "strelka", -->

<!--                                               grepl("MUTECT2", simple_name) ~ "mutect2", -->

<!--                                               grepl("FREEBAYES", simple_name) ~ "freebayes", -->

<!--                                               TRUE ~ "other")) %>% -->

<!--                                         group_by(intervals,tool, sample) %>% -->

<!--                                         summarise(sum = sum(workdir_GB)) -->

<!-- merged_formatted_vc_storage_sum$intervals <- as.factor(merged_formatted_vc_storage_sum$intervals) -->

<!-- x_axis <- function(type) { -->

<!--       if(identical('mapping', type)) { -->

<!--         scale_x_continuous(breaks = c(0, 4, 8, 12, 16), labels = c(0, 4, 8, 12, 16)) } -->

<!--       else { -->

<!--         scale_x_continuous(breaks = c(1, 125, 124, 375), labels = c(1, 125, 124, 375)) -->

<!--       } -->

<!--     } -->

<!-- ``` -->

<!-- ```{r} -->

<!-- line <- ggline(merged_formatted_vc_line_time_max, x = "intervals", y = "sum",  -->

<!--                group="tool",color="tool", palette = cbPalette, numeric.x.axis = FALSE) -->

<!--     line -->

<!--     bar <- ggbarplot(merged_formatted_vc_storage_sum, x="intervals", y="sum", -->

<!--                  fill = "tool", color = "tool", -->

<!--                 position = position_dodge(0.7), palette = cbPalette) #+ -->

<!--       # labs(y = "work dir (GB)", x = xaxis) + -->

<!--       # theme(axis.title.x = element_text(size=15), -->

<!--       #       axis.title.y = element_text(size=15), -->

<!--       #       plot.title = element_text(size = 20, hjust = 0.), -->

<!--       #       legend.text = element_text(size = 13)) + -->

<!--       # rremove("legend.title") -->

<!--     plot <- ggarrange(line, bar) -->

<!--     ann_plot <- annotate_figure(plot, top = text_grob("title", face = "bold", size = 14)) -->

<!--     ann_plot -->

<!-- ``` -->

# Package versions:

```{r, echo=F}
installed.packages()[names(sessionInfo()$otherPkgs), "Version"]
```
